{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>[ADVSTAT] Naive Bayesian Spam Filtering Tutorial</h1> <br>\n",
    "<b>Author:</b> Jan Kristoffer Cheng and Shayane Tan\n",
    "<hr>\n",
    "<h3>Description</h3>\n",
    "<p>In this notebook, we implemented the </p>\n",
    "<h4>References:</h4>\n",
    "<ol>\n",
    "    <li>Androutsopoulos, I., Koutsias, J., Chandrinos, K. V., Paliouras, G., & Spyropoulos, C. D. (2000). An evaluation of naive bayesian anti-spam filtering. arXiv preprint cs/0006013.</li>\n",
    "    <li>Sch√ºtze, H. (2008). 13: Text Classification and Naive Bayes. In Introduction to Information Retrieval (pp. 253-286). Cambridge University Press. Retrieved December 8, 2016, from http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf</li>\n",
    "    <li>Metsis, V., Androutsopoulos, I., & Paliouras, G. (2006, July). Spam filtering with naive bayes-which naive bayes?. In CEAS (pp. 27-28).</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start off, let's import the necessary packages.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, content):\n",
    "        self.content = content\n",
    "        self.mutualInfo = 0\n",
    "        self.notPresentSpamCount = 0\n",
    "        self.notPresentLegitCount = 0\n",
    "        self.presentSpamCount = 0\n",
    "        self.presentLegitCount = 0\n",
    "        self.spamDocumentCount = 0\n",
    "        self.legitDocumentCount = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The Word class represents each distinct word in the dataset. It contains the document frequencies for both spam and legitimate categories.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PartFolder:\n",
    "    def __init__(self):\n",
    "        self.spamEmail = []\n",
    "        self.legitEmail = []\n",
    "\n",
    "    def addSpamEmail(self, email):\n",
    "        self.spamEmail.append(email)\n",
    "\n",
    "    def addLegitEmail(self, email):\n",
    "        self.legitEmail.append(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The PartFolder class represents the different part folders in the dataset. It categorizes the emails to its corresponding class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user input variables\n",
    "threshold_lambda = 1\n",
    "threshold_t = threshold_lambda/(1+threshold_lambda)\n",
    "file_path = 'spam emails\\\\bare\\\\part'\n",
    "\n",
    "#training variables\n",
    "trainingDistinctWords = {} #dictionary of Word(s)\n",
    "trainingSpamEmails = [] #list of spam emails in the training set\n",
    "trainingLegitEmails = [] #list of legitimate emails in the training set\n",
    "folderCollection = [] #list of PartFolder(s)\n",
    "\n",
    "nWordsSpam = 0\n",
    "nWordsLegit = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here, we initialized the necessary variables to contain the words' document frequencies (trainingDistinctWords), training set of spam emails (trainingSpamEmails), training set of legit emails (trainingLegitEmails), and the collection of all preloaded emails or dataset (folderCollection). This is also where the threshold is defined for the spam classification based on the Naive Bayes result. The threshold will be discussed further later.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preload email dataset:</b>\n",
    "<p>In order to lessen the running time, let us first pre-load the email dataset before training the system and evaluating all results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadEmails(path):\n",
    "    print(\"Loading emails...\")\n",
    "    for i in range(1,11):\n",
    "        partPath = path + str(i)\n",
    "        partFolder = PartFolder()\n",
    "        for filename in os.listdir(partPath):\n",
    "            content = open(partPath + '\\\\' + filename).read()\n",
    "            if filename.startswith('sp'):\n",
    "                partFolder.addSpamEmail(content)\n",
    "            else:\n",
    "                partFolder.addLegitEmail(content)\n",
    "\n",
    "        folderCollection.append(partFolder)\n",
    "    \n",
    "    print(\"Finish loading emails...\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare training dataset:</b>\n",
    "<p>Then, let us prepare our training set by observing the frequencies of the different distinct words.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preparingTrainingSet(testingIndex):\n",
    "\n",
    "    print(\"Preparing training set...\")\n",
    "    #re-initialized the necessary variables for each iteration when implementing the 10-fold cross validation\n",
    "    trainingSpamEmails = []\n",
    "    trainingLegitEmails = []\n",
    "    trainingDistinctWords = {}\n",
    "\n",
    "    for i in range(len(self.folderCollection)):\n",
    "        if i != testingIndex:\n",
    "            self.trainingSpamEmails += self.folderCollection[i].spamEmail\n",
    "            self.trainingLegitEmails += self.folderCollection[i].legitEmail\n",
    "\n",
    "    for email in self.trainingLegitEmails:\n",
    "        email = email.split()\n",
    "        tokenizedEmail = set(email)\n",
    "\n",
    "        #count term frequencies\n",
    "        for token in tokenizedEmail:\n",
    "            if token in self.trainingDistinctWords:\n",
    "                word = self.trainingDistinctWords.get(token)\n",
    "                word.presentLegitCount += 1\n",
    "                word.notPresentLegitCount -= 1\n",
    "            else:\n",
    "                word = Word(token)\n",
    "                word.presentLegitCount = 1\n",
    "                word.notPresentLegitCount = len(self.trainingLegitEmails) - 1\n",
    "                word.presentSpamCount = 0\n",
    "                word.notPresentSpamCount = len(self.trainingSpamEmails)\n",
    "                self.trainingDistinctWords[token] = word\n",
    "\n",
    "\n",
    "\n",
    "    for email in self.trainingSpamEmails:\n",
    "        email = email.split()\n",
    "        tokenizedEmail = set(email)\n",
    "        for token in tokenizedEmail:\n",
    "            if token in self.trainingDistinctWords:\n",
    "                word = self.trainingDistinctWords.get(token)\n",
    "                word.presentSpamCount += 1\n",
    "                word.notPresentSpamCount -= 1\n",
    "            else:\n",
    "                word = Word(token)\n",
    "                word.presentSpamCount = 1\n",
    "                word.notPresentSpamCount = len(self.trainingSpamEmails) - 1\n",
    "                word.presentLegitCount = 0\n",
    "                word.notPresentLegitCount = len(self.trainingLegitEmails)\n",
    "                self.trainingDistinctWords[token] = word\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Training distinct words: \", len(self.trainingDistinctWords))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
